{
    "summary": "The code includes a custom document writer class for managing line and character limits, functions for file processing, command-line argument parsing, and LLM utilization with helper functions. It defines a `split_and_process_lines()` function to process content using a given `process_queue`.",
    "details": [
        {
            "comment": "This code defines a custom document writer class with parameters for specifying the output location and character limit. It also handles line splitting if necessary, and provides grace period support in line splitting. The code uses various imports such as llm, beartype, argparse, and os modules.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/custom_doc_writer.py\":0-36",
            "content": "# will implement the doc writer myself.\n# first thing: visualize the progress.\n# TODO: specify location like: module -> filename -> block name (class/method) -> lineno\n# usually the line is not so long. but if it does, we cut it.\nfrom typing import Callable\nimport random\nimport argparse, os\nimport json\nfrom beartype import beartype\nfrom beartype.door import is_bearable\nfrom beartype.vale import Is\nfrom typing import Annotated, Optional  # <--------------- if Python \u2265 3.9.0\nfrom llm import LLM, llm_context  # type:ignore\nimport copy\nfrom codepiece_summarizer import comment_summarizer  # type:ignore\nfrom typing import TypedDict\nUTF8 = \"utf-8\"\nDEFAULT_LINE_LIMIT = 50\nDEFAULT_GRACE_PERIOD_CHAR_LIMIT = 100  # TODO: grace period support in line spliting\nclass CustomDocumentWriterParams(TypedDict):\n    location_prefix: Optional[str]\nCUSTOM_DOC_WRITER_PARAMS = CustomDocumentWriterParams(location_prefix=None)\nDEFAULT_CHAR_LIMIT = 1000\nNonEmptyString = Annotated[str, Is[lambda str_obj: len(str_obj.strip()) > 0]]\nclass DocumentProcessingException(Exception):"
        },
        {
            "comment": "This code defines a class called `DocProcessQueue` for processing documents. It takes a method that processes text comments with location and content information, along with optional parameters such as character and line limits, and grace period character limit. The class initializes an instance of the provided method and allows adding new documents to the queue for processing.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/custom_doc_writer.py\":37-82",
            "content": "    ...  # placeholder\nclass UnableToCutByLineLimit(Exception):\n    ...\nclass ZeroCutIndex(Exception):\n    def __init__(self):\n        super().__init__(\"Unable to cut with zero cut index.\")\n@beartype\ndef commentProcessMethodFactory(\n    model: LLM, prompt_generator: Callable[[str, str, str], str]\n):\n    @beartype\n    def commentProcessMethod(\n        content: NonEmptyString,\n        location: NonEmptyString,\n        previous_comment: str = \"\",\n    ) -> tuple[bool, str]:\n        success = False\n        prompt = prompt_generator(content, location, previous_comment)\n        result = model.run(prompt)\n        success = True\n        return success, result\n    return commentProcessMethod\nclass DocProcessingItem(TypedDict):\n    comment: str\n    location: str\n    content: str\n@beartype\nclass DocProcessQueue:\n    def __init__(\n        self,\n        process_method: Callable[[str, str, str], tuple[bool, str]],\n        filepath: str,\n        char_limit: int = DEFAULT_CHAR_LIMIT,\n        line_limit: int = DEFAULT_LINE_LIMIT,\n        grace_period_char_limit: int = DEFAULT_GRACE_PERIOD_CHAR_LIMIT,"
        },
        {
            "comment": "This code initializes the class attributes and sets up the necessary data structures for processing documents. It accepts parameters like sample size, file path, and usage of previous comments. It also initializes counters and limits for character and line counts within a document.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/custom_doc_writer.py\":83-111",
            "content": "        sample_size: Optional[int] = None,\n        use_previous_comment: bool = True,\n    ):\n        self.init_limits_and_counters(char_limit, line_limit, grace_period_char_limit)\n        self.init_storage()\n        self.init_sample(sample_size)\n        self.process_method = process_method\n        self.filepath = filepath\n        self.use_previous_comment = use_previous_comment\n    def init_sample(self, sample_size: Optional[int]):\n        self.sample_size = sample_size  # type: ignore\n        self.random_sample = self.sample_size is not None\n    def init_storage(self):\n        self.queue = []\n        self.locations = []\n        self.result_all: list[DocProcessingItem] = []\n        self.previous_comment = \"\"\n    def init_limits_and_counters(\n        self, char_limit: int, line_limit: int, grace_period_char_limit: int\n    ):\n        self.char_limit = char_limit\n        self.line_limit = line_limit\n        self.grace_period_char_limit = grace_period_char_limit\n        self.char_count = 0\n        self.line_count = 0"
        },
        {
            "comment": "This code is responsible for handling line and character limit exceeding issues in a document writer. It includes functions to check if the limits are exceeded, remove content from the document based on cut index, prepare the remaining content and location, and retrieve the cut and remained parameters by character limit.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/custom_doc_writer.py\":112-142",
            "content": "        # self.grace_period = False\n    def char_limit_exceeded(self):\n        return self.char_count > self.char_limit\n    def line_limit_exceeded(self):\n        return self.line_count > self.line_limit\n    def strip_storage_by_cut_index(self, cut_index: int):\n        self.queue = self.queue[cut_index:]\n        self.locations = self.locations[cut_index:]\n    def prepare_content_and_location(\n        self, cut_index: int, cut_content: Optional[str] = None\n    ):\n        from_lineno, to_lineno = self.locations[0], self.locations[cut_index - 1]\n        lines = self.queue[:cut_index]\n        if cut_content is not None:\n            lines[-1] = cut_content\n        content = \"\\n\".join(lines)\n        location = f'\"{self.filepath}\":{from_lineno}-{to_lineno}'\n        return content, location\n    def get_cut_and_remained_params_by_char_limit(self):\n        char_count = 0\n        remained_content = None\n        cut_content = None\n        remained_location = None\n        cut_index = None\n        for index, line in enumerate(self.queue):"
        },
        {
            "comment": "This code checks if the character count in a line exceeds the given limit. If it does, it determines whether to cut or split the line and returns the cut index, content, remaining content, and location.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/custom_doc_writer.py\":143-166",
            "content": "            char_count += len(line)\n            if char_count > self.char_limit:\n                if char_count < self.char_limit + self.grace_period_char_limit:\n                    cut_content = line\n                    remained_content = \"\"\n                    remained_location = self.locations[index]\n                    cut_index = index + 1\n                else:\n                    reverse_cut_point = char_count - self.char_limit\n                    cut_point = len(line) - reverse_cut_point\n                    cut_content = line[:cut_point]\n                    remained_content = line[cut_point:]\n                    remained_location = self.locations[index]\n                    cut_index = index + 1\n                break\n        return cut_index, cut_content, remained_content, remained_location\n    def process_by_char_limit(self):\n        (\n            cut_index,\n            cut_content,\n            remained_content,\n            remained_location,\n        ) = self.get_cut_and_remained_params_by_char_limit()"
        },
        {
            "comment": "Code is responsible for handling document writer operations, including preparing content and location, stripping storage by cut index, updating counters, getting cut parameters by line limit, and processing documents by line limit.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/custom_doc_writer.py\":167-196",
            "content": "        content, location = self.prepare_content_and_location(\n            cut_index, cut_content  # type:ignore\n        )\n        self.strip_storage_by_cut_index(cut_index)  # type:ignore\n        if remained_content:\n            self.queue.insert(0, remained_content)\n            self.locations.insert(0, remained_location)\n        return content, location\n    def update_counters(self):\n        self.char_count = len(\"\".join(self.queue))\n        self.line_count = len(self.queue)\n    def get_cut_params_by_line_limit(self, final: bool):\n        if self.line_count > self.line_limit:\n            cut_index = self.line_limit\n        elif final:\n            cut_index = self.line_count\n        else:\n            raise UnableToCutByLineLimit(\n                f\"Current line count {self.line_count} below limit {self.line_limit}\"\n            )\n        if cut_index == 0:\n            raise ZeroCutIndex()\n        cut_content = None\n        return cut_index, cut_content\n    def process_by_line_limit(self, final=False):\n        cut_index, cut_content = self.get_cut_params_by_line_limit(final)"
        },
        {
            "comment": "This code prepares content and location, strips storage by cut index, returns content and location, processes content and location based on limits, iterates over all content and location pairs, and processes a given content and location pair.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/custom_doc_writer.py\":197-227",
            "content": "        content, location = self.prepare_content_and_location(cut_index, cut_content)\n        self.strip_storage_by_cut_index(cut_index)\n        return content, location\n    def process_by_limit(self, final=False):\n        processed = True\n        content = \"\"\n        location = \"\"\n        if self.char_limit_exceeded():\n            content, location = self.process_by_char_limit() # here we use grace period\n        elif self.line_limit_exceeded() or final:\n            content, location = self.process_by_line_limit(final=final)\n        else:\n            processed = False\n        if processed:\n            self.update_counters()\n        return processed, content, location\n    def iterate_all_content_and_location_pairs(self):\n        while True:\n            try:\n                processed, content, location = self.process_by_limit(final=True)\n                if processed:\n                    yield content, location\n                else:\n                    break\n            except ZeroCutIndex:\n                break\n    def process_content_and_location_pair(self, content: str, location: str):"
        },
        {
            "comment": "The code defines a class with methods for processing code, collecting all content and location pairs, and sampling content and location pairs. The processed result is returned as a DocProcessingItem object.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/custom_doc_writer.py\":228-256",
            "content": "        success, result = self.process_method(\n            content,\n            location,\n            **(\n                {}\n                if not self.use_previous_comment\n                else dict(previous_comment=self.previous_comment)\n            ),  # type:ignore\n        )\n        if not success:\n            raise DocumentProcessingException(\"Failed to process code at:\", location)\n        self.previous_comment = result\n        ret = DocProcessingItem(\n            comment=result, location=location, content=content  # type:ignore\n        )\n        return ret\n    def collect_all_content_and_location_pairs(self):\n        ret = []\n        for content, location in self.iterate_all_content_and_location_pairs():\n            if is_bearable(content, NonEmptyString):\n                it = (content, location)\n                ret.append(it)\n        return ret\n    def sample_content_and_location_pairs(self):\n        pairs = self.collect_all_content_and_location_pairs()\n        pair_count = len(pairs)\n        if self.random_sample:"
        },
        {
            "comment": "Function \"sample_content_and_location_pairs\" takes a list of pairs and returns a random sample of pairs based on the sample size.\n\n\"process_and_collect_all\" iterates through each content and location pair, processes them using another method, and appends the results to the result_all list. It then returns a copy of result_all.\n\n\"update_counter_after_push\" increments character count by the length of the input content and line count by 1.\n\n\"push\" adds the input content and lineno to the queue and locations lists, and calls update_counter_after_push method.\n\n\"split_by_line\" splits a string into a list of lines based on the specified newline character.\n\n\"process_content_and_get_result\" processes each line in the content using a separate method \"iterate_and_push_line_to_process_queue\", and returns the results.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/custom_doc_writer.py\":257-287",
            "content": "            self.sample_size: int\n            if pair_count > self.sample_size:\n                pairs = random.sample(pairs, k=self.sample_size)\n        return pairs\n    def process_and_collect_all(self):\n        for content, location in self.sample_content_and_location_pairs():\n            it = self.process_content_and_location_pair(content, location)\n            self.result_all.append(it)\n        return copy.copy(self.result_all)\n    def update_counter_after_push(self, content: str):\n        self.char_count += len(content)\n        self.line_count += 1\n    def push(self, content: str, lineno: int):\n        if is_bearable(content, NonEmptyString):\n            self.queue.append(content)\n            self.locations.append(lineno)\n            self.update_counter_after_push(content)  # type:ignore\n@beartype\ndef split_by_line(content: str, newline=\"\\n\"):\n    return content.split(newline)\n@beartype\ndef process_content_and_get_result(process_queue: DocProcessQueue, content: str):\n    @beartype\n    def iterate_and_push_line_to_process_queue(lines: list[str]):"
        },
        {
            "comment": "The code defines a function `split_and_process_lines()` that splits the given `content` into lines and processes them using a `process_queue`. It returns the processed lines. The `assert_exists_as_absolute_directory(basepath: str)` asserts that `basepath` is an absolute directory path, while `join_and_assert_exists_as_absolute_directory(basepath: str, name: str)` joins `basepath` and `name` to create a new absolute directory path, asserts its existence, and returns it. The code also parses command-line arguments using `argparse.ArgumentParser()`.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/custom_doc_writer.py\":288-325",
            "content": "        for lineno, line in enumerate(lines):\n            process_queue.push(line, lineno)\n    def split_and_process_lines():\n        lines = split_by_line(content)\n        iterate_and_push_line_to_process_queue(lines)\n        return process_queue.process_and_collect_all()\n    return split_and_process_lines()\n@beartype\ndef assert_exists_as_absolute_directory(basepath: str):\n    assert os.path.isabs(basepath)\n    assert os.path.isdir(basepath)\n@beartype\ndef join_and_assert_exists_as_absolute_directory(basepath: str, name: str):\n    joined_path = os.path.join(basepath, name)\n    assert_exists_as_absolute_directory(joined_path)\n    return joined_path\ndef parse_arguments():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \"-d\",\n        \"--document_dir\",\n        help=f\"document directory, contains 'src' as source code directory, 'doc' as comment json directory\",\n    )\n    parser.add_argument(\n        \"-u\",\n        \"--repository_url\",\n        help=f\"url of source code repository\",\n    )\n    args = parser.parse_args()"
        },
        {
            "comment": "This code defines a function that processes content and returns a DocProcessingResult object. It also includes a helper function, summary_code_comment_return_value, that summarizes a list of comments. The DocProcessingItem class is used to store details for each processing item.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/custom_doc_writer.py\":327-359",
            "content": "    document_dir = args.document_dir\n    repository_url = args.repository_url\n    assert_exists_as_absolute_directory(document_dir)\n    join_and_assert_exists_as_absolute_directory(document_dir, \"src\")\n    join_and_assert_exists_as_absolute_directory(document_dir, \"doc\")\n    return document_dir, repository_url\n@beartype\ndef summary_code_comment_return_value(ret: list[DocProcessingItem]):\n    comment_list = [elem[\"comment\"] for elem in ret]\n    summary = comment_summarizer(comment_list)\n    return summary\nclass DocProcessingResult(TypedDict):\n    summary: str\n    details: list[DocProcessingItem]\n@beartype\ndef process_content_and_return_result(\n    model: LLM,\n    prompt_generator: Callable[[str, str, str], str],\n    code_file_path: str,\n    content: str,\n    char_limit: int = DEFAULT_CHAR_LIMIT,\n    line_limit: int = DEFAULT_LINE_LIMIT,\n    sample_size: Optional[int] = None,\n    use_previous_comment: bool = True,\n) -> DocProcessingResult:\n    commentProcessMethod = commentProcessMethodFactory(model, prompt_generator)"
        },
        {
            "comment": "This code defines a function that processes documents using a custom document writer. It uses a DocProcessQueue to process the content and returns a summary and details of the processing result. The code also includes helper functions for reading files, serializing dictionaries, and writing results.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/custom_doc_writer.py\":360-394",
            "content": "    process_queue = DocProcessQueue(\n        commentProcessMethod,\n        code_file_path,\n        char_limit=char_limit,\n        line_limit=line_limit,\n        sample_size=sample_size,\n        use_previous_comment=use_previous_comment,\n    )\n    result_all = process_content_and_get_result(process_queue, content)\n    summary = summary_code_comment_return_value(result_all)\n    data = DocProcessingResult(summary=summary, details=result_all)\n    del process_queue\n    return data\n@beartype\ndef read_file(file_path: str, encoding=UTF8):\n    with open(file_path, \"r\", encoding=encoding) as f:\n        content = f.read()\n    return content\n@beartype\ndef serialize_dict_and_write_to_file(data_dict: dict, file_path: str, encoding=UTF8):\n    with open(file_path, \"w+\", encoding=encoding) as f:\n        f.write(json.dumps(data_dict, indent=4))\n@beartype\ndef process_code_and_write_result(\n    model: LLM,\n    prompt_generator: Callable[[str, str, str], str],\n    code_file_path: str,\n    output_path: str,\n    char_limit: int = DEFAULT_CHAR_LIMIT,"
        },
        {
            "comment": "Code is a custom document writer function that reads input code file, processes the content using a provided model and prompt generator, and writes the output to an specified file path. It also includes helper functions for filtering empty elements in a list and generating location components for storage locations.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/custom_doc_writer.py\":395-430",
            "content": "    line_limit: int = DEFAULT_LINE_LIMIT,\n    sample_size: Optional[int] = None,\n    use_previous_comment=True,\n) -> DocProcessingResult:\n    content = read_file(code_file_path)\n    data = process_content_and_return_result(\n        model,\n        prompt_generator,\n        code_file_path,\n        content,\n        char_limit=char_limit,\n        line_limit=line_limit,\n        sample_size=sample_size,\n        use_previous_comment=use_previous_comment,\n    )\n    serialize_dict_and_write_to_file(data, output_path)  # type:ignore\n    return data\n@beartype\ndef filter_empty_elements(mlist: list):\n    return [elem for elem in mlist if elem]\n# TODO: check if is relative path only\n@beartype\ndef generate_location_component(location: str):\n    location_prefix = CUSTOM_DOC_WRITER_PARAMS.get(\"location_prefix\", None)\n    if isinstance(location_prefix, str):\n        lp = '\"' + location_prefix + \"/src/\"\n        assert location.startswith(lp)\n        location = '\"' + location[len(lp) :]\n    return f\"\"\"Storage location: {location}\"\"\"\n@beartype"
        },
        {
            "comment": "This code defines functions for generating prompt components in a document. The 'generate_prompt_components' function takes code, location, programming language, and previous comment as inputs and returns a list of formatted components for a prompt including the location, previous comment, code, and a placeholder comment.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/custom_doc_writer.py\":431-472",
            "content": "def generate_previous_comment_component(previous_comment: str):\n    return (\n        f\"\"\"Previous code comment:\n{previous_comment}\"\"\"\n        if previous_comment\n        else \"\"\n    )\n@beartype\ndef generate_code_component(programming_language: str, code: str):\n    return f\"\"\"Code:\n```{programming_language}\n{code}\n```\"\"\"\ndef generate_comment_coponent():\n    return \"\"\"Comment for code:\n\"\"\"\n@beartype\ndef generate_prompt_components(\n    code: str, location: str, programming_language: str, previous_comment: str\n):\n    location_component = generate_location_component(location)\n    previous_comment_component = generate_previous_comment_component(previous_comment)\n    code_component = generate_code_component(programming_language, code)\n    comment_component = generate_comment_coponent()\n    components = [\n        location_component,\n        previous_comment_component,\n        code_component,\n        comment_component,\n    ]\n    return components\n@beartype\ndef assemble_prompt_components(components: list[str]):\n    components = filter_empty_elements(components)"
        },
        {
            "comment": "This code defines functions that generate prompts for generating comments on code. The `generate_prompt_base` function creates a base prompt for the LLM, while `generate_prompt_generator` generates more specific prompts based on the programming language and code location. The `construct_llm_and_write_code_comment` function uses these prompts to generate comments using an LLM (Language Model) in the context of the provided prompt base.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/custom_doc_writer.py\":473-507",
            "content": "    ret = \"\\n\".join(components)\n    return ret\n@beartype\ndef generate_prompt_generator(programming_language: str):\n    @beartype\n    def prompt_generator(code: str, location: str, previous_comment: str = \"\"):\n        components = generate_prompt_components(\n            code, location, programming_language, previous_comment\n        )\n        ret = assemble_prompt_components(components)\n        return ret\n    return prompt_generator\n@beartype\ndef generate_prompt_base(word_limit: int):\n    return f\"\"\"You are reading code from codebase in chunks. You would understand what the code is doing and return brief comments (under {word_limit} words).\"\"\"\n@beartype\ndef construct_llm_and_write_code_comment(\n    code_file_path: str,\n    output_path: str,\n    programming_language: str = \"\",\n    word_limit: int = 15,\n    use_previous_comment: bool = False,  # different from our blog summarizer.\n):\n    prompt_base = generate_prompt_base(word_limit)\n    prompt_generator = generate_prompt_generator(programming_language)\n    with llm_context(prompt_base) as model:"
        },
        {
            "comment": "This code defines a function `main()` which parses arguments, sets the language and file paths, and calls another function `construct_llm_and_write_code_comment()`. The main function then runs as the entry point when the script is executed directly.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/custom_doc_writer.py\":508-530",
            "content": "        ret = process_code_and_write_result(\n            model,\n            prompt_generator,\n            code_file_path,\n            output_path,\n            use_previous_comment=use_previous_comment,\n        )\n    return ret\ndef main():\n    document_dir, repository_url = parse_arguments()\n    # programming_language, code_file_path, output_path = parse_arguments()\n    programming_language = \"\"\n    code_file_path = os.path.join(document_dir, \"src\")\n    output_path = \"doc\"\n    construct_llm_and_write_code_comment(\n        code_file_path, output_path, programming_language=programming_language\n    )\nif __name__ == \"__main__\":\n    main()"
        }
    ]
}