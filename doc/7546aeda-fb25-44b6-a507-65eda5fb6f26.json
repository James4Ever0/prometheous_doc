{
    "summary": "This code develops a custom document writer class with progress visualization and queue-based processing of comments. It includes functions for content processing, counter updating, line splitting, and language model usage, likely part of a larger system used for summarization or analysis tasks. The main function handles argument parsing, setting default values, and executing the prompt generation process.",
    "details": [
        {
            "comment": "This code is a part of a custom document writer, which will implement the document writing functionality. It begins by visualizing progress and specifies the location using a prefix. The code also mentions that long lines may be cut if necessary. It imports various modules and classes for handling typing, file operations, and line management. It defines some constants like UTF8 encoding, default character limit, and grace period character limit. Finally, it provides a dictionary-like class CustomDocumentWriterParams for configuring the writer's parameters with optional location prefix and project name.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/custom_doc_writer.py\":0-36",
            "content": "# will implement the doc writer myself.\n# first thing: visualize the progress.\n# TODO: specify location like: module -> filename -> block name (class/method) -> lineno\n# usually the line is not so long. but if it does, we cut it.\nfrom typing import Callable\nimport random\nimport argparse, os\nimport json\nfrom beartype import beartype\nfrom beartype.door import is_bearable\nfrom beartype.vale import Is\nfrom typing import Annotated, Optional  # <--------------- if Python \u2265 3.9.0\nfrom llm import LLM, llm_context  # type:ignore\nimport copy\nfrom codepiece_summarizer import comment_summarizer  # type:ignore\nfrom typing import TypedDict\nUTF8 = \"utf-8\"\nDEFAULT_LINE_LIMIT = 50\nDEFAULT_GRACE_PERIOD_CHAR_LIMIT = 100  # TODO: grace period support in line spliting\nclass CustomDocumentWriterParams(TypedDict):\n    location_prefix: Optional[str]\n    project_name: Optional[str]\nCUSTOM_DOC_WRITER_PARAMS = CustomDocumentWriterParams(\n    location_prefix=None, project_name=None\n)\nDEFAULT_CHAR_LIMIT = 1000\nNonEmptyString = Annotated[str, Is[lambda str_obj: len(str_obj.strip()) > 0]]"
        },
        {
            "comment": "This code defines a `DocProcessQueue` class for processing document comments in a queue-like manner. It utilizes a `process_method` that takes a comment, location, and previous comment as input to generate a response. The class also supports line and character limits, and throws exceptions like `UnableToCutByLineLimit` and `ZeroCutIndex`.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/custom_doc_writer.py\":39-84",
            "content": "class DocumentProcessingException(Exception):\n    ...  # placeholder\nclass UnableToCutByLineLimit(Exception):\n    ...\nclass ZeroCutIndex(Exception):\n    def __init__(self):\n        super().__init__(\"Unable to cut with zero cut index.\")\n@beartype\ndef commentProcessMethodFactory(\n    model: LLM, prompt_generator: Callable[[str, str, str], str]\n):\n    @beartype\n    def commentProcessMethod(\n        content: NonEmptyString,\n        location: NonEmptyString,\n        previous_comment: str = \"\",\n    ) -> tuple[bool, str]:\n        success = False\n        prompt = prompt_generator(content, location, previous_comment)\n        result = model.run(prompt)\n        success = True\n        return success, result\n    return commentProcessMethod\nclass DocProcessingItem(TypedDict):\n    comment: str\n    location: str\n    content: str\n@beartype\nclass DocProcessQueue:\n    def __init__(\n        self,\n        process_method: Callable[[str, str, str], tuple[bool, str]],\n        filepath: str,\n        char_limit: int = DEFAULT_CHAR_LIMIT,\n        line_limit: int = DEFAULT_LINE_LIMIT,"
        },
        {
            "comment": "This code initializes a custom document writer class with various parameters such as character limit, line limit, grace period character limit, optional sample size, and whether to use the previous comment. The class methods initialize internal data structures like queues, lists, and result all list. It also sets the file path for processing.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/custom_doc_writer.py\":85-111",
            "content": "        grace_period_char_limit: int = DEFAULT_GRACE_PERIOD_CHAR_LIMIT,\n        sample_size: Optional[int] = None,\n        use_previous_comment: bool = True,\n    ):\n        self.init_limits_and_counters(char_limit, line_limit, grace_period_char_limit)\n        self.init_storage()\n        self.init_sample(sample_size)\n        self.process_method = process_method\n        self.filepath = filepath\n        self.use_previous_comment = use_previous_comment\n    def init_sample(self, sample_size: Optional[int]):\n        self.sample_size = sample_size  # type: ignore\n        self.random_sample = self.sample_size is not None\n    def init_storage(self):\n        self.queue = []\n        self.locations = []\n        self.result_all: list[DocProcessingItem] = []\n        self.previous_comment = \"\"\n    def init_limits_and_counters(\n        self, char_limit: int, line_limit: int, grace_period_char_limit: int\n    ):\n        self.char_limit = char_limit\n        self.line_limit = line_limit\n        self.grace_period_char_limit = grace_period_char_limit"
        },
        {
            "comment": "This code defines a class with methods to check character and line limits, remove content exceeding those limits, prepare the remaining content and location for output. It also includes functions to get cut information based on character limit.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/custom_doc_writer.py\":113-144",
            "content": "        self.char_count = 0\n        self.line_count = 0\n        # self.grace_period = False\n    def char_limit_exceeded(self):\n        return self.char_count > self.char_limit\n    def line_limit_exceeded(self):\n        return self.line_count > self.line_limit\n    def strip_storage_by_cut_index(self, cut_index: int):\n        self.queue = self.queue[cut_index:]\n        self.locations = self.locations[cut_index:]\n    def prepare_content_and_location(\n        self, cut_index: int, cut_content: Optional[str] = None\n    ):\n        from_lineno, to_lineno = self.locations[0], self.locations[cut_index - 1]\n        lines = self.queue[:cut_index]\n        if cut_content is not None:\n            lines[-1] = cut_content\n        content = \"\\n\".join(lines)\n        location = f'\"{self.filepath}\":{from_lineno}-{to_lineno}'\n        return content, location\n    def get_cut_and_remained_params_by_char_limit(self):\n        char_count = 0\n        remained_content = None\n        cut_content = None\n        remained_location = None\n        cut_index = None"
        },
        {
            "comment": "This function loops through the queue of lines, tracks character count, and determines when to split a line based on a specified char limit. It returns indices for cut and remained content, along with their respective locations.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/custom_doc_writer.py\":145-169",
            "content": "        for index, line in enumerate(self.queue):\n            char_count += len(line)\n            if char_count > self.char_limit:\n                if char_count < self.char_limit + self.grace_period_char_limit:\n                    cut_content = line\n                    remained_content = \"\"\n                    remained_location = self.locations[index]\n                    cut_index = index + 1\n                else:\n                    reverse_cut_point = char_count - self.char_limit\n                    cut_point = len(line) - reverse_cut_point\n                    cut_content = line[:cut_point]\n                    remained_content = line[cut_point:]\n                    remained_location = self.locations[index]\n                    cut_index = index + 1\n                break\n        return cut_index, cut_content, remained_content, remained_location\n    def process_by_char_limit(self):\n        (\n            cut_index,\n            cut_content,\n            remained_content,\n            remained_location,\n        ) = self.get_cut_and_remained_params_by_char_limit()"
        },
        {
            "comment": "This code contains a custom document writer class with methods for preparing content and location, stripping storage by cut index, updating counters based on queue content, getting cut parameters by line limit, and processing documents by line limit.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/custom_doc_writer.py\":170-199",
            "content": "        content, location = self.prepare_content_and_location(\n            cut_index, cut_content  # type:ignore\n        )\n        self.strip_storage_by_cut_index(cut_index)  # type:ignore\n        if remained_content:\n            self.queue.insert(0, remained_content)\n            self.locations.insert(0, remained_location)\n        return content, location\n    def update_counters(self):\n        self.char_count = len(\"\".join(self.queue))\n        self.line_count = len(self.queue)\n    def get_cut_params_by_line_limit(self, final: bool):\n        if self.line_count > self.line_limit:\n            cut_index = self.line_limit\n        elif final:\n            cut_index = self.line_count\n        else:\n            raise UnableToCutByLineLimit(\n                f\"Current line count {self.line_count} below limit {self.line_limit}\"\n            )\n        if cut_index == 0:\n            raise ZeroCutIndex()\n        cut_content = None\n        return cut_index, cut_content\n    def process_by_line_limit(self, final=False):\n        cut_index, cut_content = self.get_cut_params_by_line_limit(final)"
        },
        {
            "comment": "The code implements a custom document writer that processes text based on character and line limits, yielding content and location pairs until either the limit is reached or no more cuts can be made. It also updates counters for each processed pair.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/custom_doc_writer.py\":200-228",
            "content": "        content, location = self.prepare_content_and_location(cut_index, cut_content)\n        self.strip_storage_by_cut_index(cut_index)\n        return content, location\n    def process_by_limit(self, final=False):\n        processed = True\n        content = \"\"\n        location = \"\"\n        if self.char_limit_exceeded():\n            content, location = self.process_by_char_limit()  # here we use grace period\n        elif self.line_limit_exceeded() or final:\n            content, location = self.process_by_line_limit(final=final)\n        else:\n            processed = False\n        if processed:\n            self.update_counters()\n        return processed, content, location\n    def iterate_all_content_and_location_pairs(self):\n        while True:\n            try:\n                processed, content, location = self.process_by_limit(final=True)\n                if processed:\n                    yield content, location\n                else:\n                    break\n            except ZeroCutIndex:\n                break"
        },
        {
            "comment": "This code defines a class with two methods: \"process_content_and_location_pair\" and \"collect_all_content_and_location_pairs\". The former processes content and location pairs, storing the result in \"self.previous_comment\", and raises an exception if it fails to process. The latter collects all content and location pairs, filtering out non-empty strings, and returns them as a list of tuples.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/custom_doc_writer.py\":230-257",
            "content": "    def process_content_and_location_pair(self, content: str, location: str):\n        success, result = self.process_method(\n            content,\n            location,\n            **(\n                {}\n                if not self.use_previous_comment\n                else dict(previous_comment=self.previous_comment)\n            ),  # type:ignore\n        )\n        if not success:\n            raise DocumentProcessingException(\"Failed to process code at:\", location)\n        self.previous_comment = result\n        ret = DocProcessingItem(\n            comment=result, location=location, content=content  # type:ignore\n        )\n        return ret\n    def collect_all_content_and_location_pairs(self):\n        ret = []\n        for content, location in self.iterate_all_content_and_location_pairs():\n            if is_bearable(content, NonEmptyString):\n                it = (content, location)\n                ret.append(it)\n        return ret\n    def sample_content_and_location_pairs(self):\n        pairs = self.collect_all_content_and_location_pairs()"
        },
        {
            "comment": "This code includes functions to process and collect content samples, update counters after pushing new content into a queue, and split content by line. The \"process_and_collect_all\" function iterates through content and location pairs, processes each pair, and appends the results to a list. The \"update_counter_after_push\" function increments character and line count counters after pushing new content into a queue. The \"split_by_line\" function splits content by a specified newline character. The \"process_content_and_get_result\" function processes the content using a DocProcessQueue and returns the result.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/custom_doc_writer.py\":258-288",
            "content": "        pair_count = len(pairs)\n        if self.random_sample:\n            self.sample_size: int\n            if pair_count > self.sample_size:\n                pairs = random.sample(pairs, k=self.sample_size)\n        return pairs\n    def process_and_collect_all(self):\n        for content, location in self.sample_content_and_location_pairs():\n            it = self.process_content_and_location_pair(content, location)\n            self.result_all.append(it)\n        return copy.copy(self.result_all)\n    def update_counter_after_push(self, content: str):\n        self.char_count += len(content)\n        self.line_count += 1\n    def push(self, content: str, lineno: int):\n        if is_bearable(content, NonEmptyString):\n            self.queue.append(content)\n            self.locations.append(lineno)\n            self.update_counter_after_push(content)  # type:ignore\n@beartype\ndef split_by_line(content: str, newline=\"\\n\"):\n    return content.split(newline)\n@beartype\ndef process_content_and_get_result(process_queue: DocProcessQueue, content: str):"
        },
        {
            "comment": "This code defines a function `split_and_process_lines()` that splits the given content into lines, pushes each line along with its line number to a `process_queue`, and then processes all lines in the queue. The code also includes two helper functions: `assert_exists_as_absolute_directory()` to check if a path is an absolute directory, and `join_and_assert_exists_as_absolute_directory()` to join a basepath with a name and assert that the joined path exists as an absolute directory. The code also parses command-line arguments using `argparse`.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/custom_doc_writer.py\":289-325",
            "content": "    @beartype\n    def iterate_and_push_line_to_process_queue(lines: list[str]):\n        for lineno, line in enumerate(lines):\n            process_queue.push(line, lineno)\n    def split_and_process_lines():\n        lines = split_by_line(content)\n        iterate_and_push_line_to_process_queue(lines)\n        return process_queue.process_and_collect_all()\n    return split_and_process_lines()\n@beartype\ndef assert_exists_as_absolute_directory(basepath: str):\n    assert os.path.isabs(basepath)\n    assert os.path.isdir(basepath)\n@beartype\ndef join_and_assert_exists_as_absolute_directory(basepath: str, name: str):\n    joined_path = os.path.join(basepath, name)\n    assert_exists_as_absolute_directory(joined_path)\n    return joined_path\ndef parse_arguments():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \"-d\",\n        \"--document_dir\",\n        help=f\"document directory, contains 'src' as source code directory, 'doc' as comment json directory\",\n    )\n    parser.add_argument(\n        \"-u\",\n        \"--repository_url\","
        },
        {
            "comment": "This code defines a function `process_content_and_return_result` that processes content, such as code or documentation, using a large language model (LLM). The function takes parameters like the LLM model instance, a prompt generator function, code file path, and the actual content. It also includes optional parameters for character limit, line limit, sample size, and whether to use the previous comment in processing. The returned result is a dictionary with a summary and details of the processed content. The `summary_code_comment_return_value` function generates a summary from a list of comments extracted from the returned details. Both functions seem to be part of a larger system that processes code or documentation, likely for summarization or analysis purposes.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/custom_doc_writer.py\":326-361",
            "content": "        help=f\"url of source code repository\",\n    )\n    args = parser.parse_args()\n    document_dir = args.document_dir\n    repository_url = args.repository_url\n    assert_exists_as_absolute_directory(document_dir)\n    join_and_assert_exists_as_absolute_directory(document_dir, \"src\")\n    join_and_assert_exists_as_absolute_directory(document_dir, \"doc\")\n    return document_dir, repository_url\n@beartype\ndef summary_code_comment_return_value(ret: list[DocProcessingItem]):\n    comment_list = [elem[\"comment\"] for elem in ret]\n    summary = comment_summarizer(comment_list)\n    return summary\nclass DocProcessingResult(TypedDict):\n    summary: str\n    details: list[DocProcessingItem]\n@beartype\ndef process_content_and_return_result(\n    model: LLM,\n    prompt_generator: Callable[[str, str, str], str],\n    code_file_path: str,\n    content: str,\n    char_limit: int = DEFAULT_CHAR_LIMIT,\n    line_limit: int = DEFAULT_LINE_LIMIT,\n    sample_size: Optional[int] = None,\n    use_previous_comment: bool = True,\n) -> DocProcessingResult:"
        },
        {
            "comment": "This code defines a function that processes code and writes the result to a file. It uses a custom document writer and involves reading files, generating prompts, and writing serialized dictionaries to files. The function takes in a language model (LLM) and a prompt generator as parameters for processing the code.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/custom_doc_writer.py\":362-394",
            "content": "    commentProcessMethod = commentProcessMethodFactory(model, prompt_generator)\n    process_queue = DocProcessQueue(\n        commentProcessMethod,\n        code_file_path,\n        char_limit=char_limit,\n        line_limit=line_limit,\n        sample_size=sample_size,\n        use_previous_comment=use_previous_comment,\n    )\n    result_all = process_content_and_get_result(process_queue, content)\n    summary = summary_code_comment_return_value(result_all)\n    data = DocProcessingResult(summary=summary, details=result_all)\n    del process_queue\n    return data\n@beartype\ndef read_file(file_path: str, encoding=UTF8):\n    with open(file_path, \"r\", encoding=encoding) as f:\n        content = f.read()\n    return content\n@beartype\ndef serialize_dict_and_write_to_file(data_dict: dict, file_path: str, encoding=UTF8):\n    with open(file_path, \"w+\", encoding=encoding) as f:\n        f.write(json.dumps(data_dict, indent=4))\n@beartype\ndef process_code_and_write_result(\n    model: LLM,\n    prompt_generator: Callable[[str, str, str], str],"
        },
        {
            "comment": "This code is part of a function that reads a file, processes its content using AI model and prompt generator, and then writes the processed data to an output file. The function takes parameters like input file path, output path, character limit, line limit, sample size (optional), and a flag to use previous comment. It uses beartype for type hints and includes helper functions for filtering empty elements and generating location components. The TODO comment suggests checking if the location is a relative path only.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/custom_doc_writer.py\":395-429",
            "content": "    code_file_path: str,\n    output_path: str,\n    char_limit: int = DEFAULT_CHAR_LIMIT,\n    line_limit: int = DEFAULT_LINE_LIMIT,\n    sample_size: Optional[int] = None,\n    use_previous_comment=True,\n) -> DocProcessingResult:\n    content = read_file(code_file_path)\n    data = process_content_and_return_result(\n        model,\n        prompt_generator,\n        code_file_path,\n        content,\n        char_limit=char_limit,\n        line_limit=line_limit,\n        sample_size=sample_size,\n        use_previous_comment=use_previous_comment,\n    )\n    serialize_dict_and_write_to_file(data, output_path)  # type:ignore\n    return data\n@beartype\ndef filter_empty_elements(mlist: list):\n    return [elem for elem in mlist if elem]\n# TODO: check if is relative path only\n@beartype\ndef generate_location_component(location: str):\n    location_prefix = CUSTOM_DOC_WRITER_PARAMS.get(\"location_prefix\", None)\n    if isinstance(location_prefix, str):\n        lp = '\"' + location_prefix + \"/src/\"\n        assert location.startswith(lp)\n        project_name = CUSTOM_DOC_WRITER_PARAMS[\"project_name\"]"
        },
        {
            "comment": "Code:\n```python\ndef generate_comment_component():\n    return \"\"\"\nComment for code in 30 words (do not repeat or rephrase the content, be concise and relevant):\"\"\"\n@beartype\ndef generate_prompt_components(\n    code: str, location: str, programming_language: str, previous_comment: str\n):\n    location_component = generate_location_component(location)\n    previous_comment_component = generate_previous_comment_component(previous_comment)\n    code_component = generate_code_component(programming_language, code)\n```",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/custom_doc_writer.py\":430-468",
            "content": "        location = (\n            '\"' + (project_name + \"/\" if project_name else \"\") + location[len(lp) :]\n        )\n    return f\"\"\"Storage location: {location}\"\"\"\n@beartype\ndef generate_previous_comment_component(previous_comment: str):\n    return (\n        f\"\"\"Previous code comment:\n{previous_comment}\"\"\"\n        if previous_comment\n        else \"\"\n    )\n@beartype\ndef generate_code_component(programming_language: str, code: str):\n    return f\"\"\"Code:\n```{programming_language}\n{code}\n```\"\"\"\ndef generate_comment_coponent():\n    # return \"\"\"Comment for code:\n    # to reduce verbosity\n    return \"\"\"\nComment for code in 30 words (do not repeat or rephrase the content, be concise and relevant):\n\"\"\"\n@beartype\ndef generate_prompt_components(\n    code: str, location: str, programming_language: str, previous_comment: str\n):\n    location_component = generate_location_component(location)\n    previous_comment_component = generate_previous_comment_component(previous_comment)\n    code_component = generate_code_component(programming_language, code)"
        },
        {
            "comment": "This code generates prompts for LLMs to read and comprehend code snippets. It assembles prompt components such as location, previous comment, code, and generated comment using the given programming language and filters out empty elements. The function returns a final prompt for the LLM to understand the code with a word limit.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/custom_doc_writer.py\":469-505",
            "content": "    comment_component = generate_comment_coponent()\n    components = [\n        location_component,\n        previous_comment_component,\n        code_component,\n        comment_component,\n    ]\n    return components\n@beartype\ndef assemble_prompt_components(components: list[str]):\n    components = filter_empty_elements(components)\n    ret = \"\\n\".join(components)\n    return ret\n@beartype\ndef generate_prompt_generator(programming_language: str):\n    @beartype\n    def prompt_generator(code: str, location: str, previous_comment: str = \"\"):\n        components = generate_prompt_components(\n            code, location, programming_language, previous_comment\n        )\n        ret = assemble_prompt_components(components)\n        return ret\n    return prompt_generator\n@beartype\ndef generate_prompt_base(word_limit: int):\n    return f\"\"\"You are reading code from codebase in chunks. You would understand what the code is doing and return brief comments (under {word_limit} words).\"\"\"\n@beartype\ndef construct_llm_and_write_code_comment("
        },
        {
            "comment": "This code is a function that takes a file path, output path, and optional parameters for programming language, word limit, and use of previous comment. It generates a prompt using the input values and a language model to process the code and write the result. The main function parses arguments, sets default values, calls the construct_llm_and_write_code_comment function, and handles execution if the module is run directly.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/custom_doc_writer.py\":506-539",
            "content": "    code_file_path: str,\n    output_path: str,\n    programming_language: str = \"\",\n    word_limit: int = 15,\n    use_previous_comment: bool = False,  # different from our blog summarizer.\n):\n    prompt_base = generate_prompt_base(word_limit)\n    prompt_generator = generate_prompt_generator(programming_language)\n    with llm_context(prompt_base) as model:\n        ret = process_code_and_write_result(\n            model,\n            prompt_generator,\n            code_file_path,\n            output_path,\n            use_previous_comment=use_previous_comment,\n        )\n    return ret\ndef main():\n    document_dir, repository_url = parse_arguments()\n    # programming_language, code_file_path, output_path = parse_arguments()\n    programming_language = \"\"\n    code_file_path = os.path.join(document_dir, \"src\")\n    output_path = \"doc\"\n    construct_llm_and_write_code_comment(\n        code_file_path, output_path, programming_language=programming_language\n    )\nif __name__ == \"__main__\":\n    main()"
        }
    ]
}