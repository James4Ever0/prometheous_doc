{
    "summary": "The CacheManager class, using TinyDB, provides cache database functions and works with records. It defines functions for generating/verifying file paths/hashes. The test environment is set up in temporary directories, iterating through source/target files to generate test parameters and print \"test passed\" if successful.",
    "details": [
        {
            "comment": "The code defines a `CacheManager` class that manages a cache database using the TinyDB library. It provides functions for reading file content in bytes, hashing file content using MD5, and initializing the database and query objects. The `CacheManager` class uses the `subkey` and `key` classes to define specific subkeys within the cache database.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/cache_db_context.py\":0-50",
            "content": "import hashlib\nimport os\nfrom contextlib import contextmanager\nfrom typing import Any, Callable, Iterable, Optional, Tuple\nimport pydantic\nimport tinydb\nfrom beartype import beartype\nimport tempfile\nUTF8 = \"utf-8\"\n@beartype\ndef read_file_bytes(filename: str):\n    with open(filename, \"rb\") as f:\n        content = f.read()\n    return content\n@beartype\ndef hash_file(filename: str):\n    content = read_file_bytes(filename)\n    hash_obj = hashlib.md5(content)\n    ret = hash_obj.hexdigest()\n    return ret\n@beartype\nclass CacheManager:\n    class subkey:\n        path = \"path\"\n        hash = \"hash\"\n    class key:\n        source = \"source\"\n        target = \"target\"\n    def __init__(self, db_path: str):\n        self.init_db(db_path)\n        self.init_query()\n    def init_db(self, db_path: str):\n        self.db_path = db_path\n        self.db = tinydb.TinyDB(db_path)\n    def init_query(self):\n        self.query = tinydb.Query()\n        self.source_path_query, self.source_hash_query = self.construct_query_by_key(\n            self.key.source"
        },
        {
            "comment": "This code defines a class with methods for comparing hash and path values, constructing queries using key and subkey attributes, and computing the source hash of a file. The class also includes a method to retrieve records by computing the source hash.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/cache_db_context.py\":51-79",
            "content": "        )\n        self.target_path_query, self.target_hash_query = self.construct_query_by_key(\n            self.key.target\n        )\n    def source_hash_eq(self, other: str):\n        return self.source_hash_query == other\n    def source_path_eq(self, other: str):\n        return self.source_path_query == other\n    def target_hash_eq(self, other: str):\n        return self.target_hash_query == other\n    def target_path_eq(self, other: str):\n        return self.target_path_query == other\n    def construct_query_by_key_and_subkey(self, key: str, subkey: str):\n        key_query = getattr(self.query, key)\n        subkey_query = getattr(key_query, subkey)\n        return subkey_query\n    def construct_query_by_key(self, key: str):\n        path_query = self.construct_query_by_key_and_subkey(key, self.subkey.path)\n        hash_query = self.construct_query_by_key_and_subkey(key, self.subkey.hash)\n        return path_query, hash_query\n    def get_record_by_computing_source_hash(self, source_path: str):\n        source_hash = hash_file(source_path)"
        },
        {
            "comment": "This code defines a class with various methods for working with records in a database. It retrieves and verifies file paths and hashes for source and target files, as well as gets the record directly using a source hash. The methods interact with the database to fetch relevant information from stored records.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/cache_db_context.py\":80-107",
            "content": "        record = self.db.get(\n            self.source_hash_eq(source_hash)\n        )  # not necessarily directly pointing to the filepath\n        return record, source_hash\n    @classmethod\n    def get_record_file_path_and_hash(cls, record: dict, key: str) -> tuple[str, str]:\n        filepath = record[key][cls.subkey.path]\n        filehash = record[key][cls.subkey.hash]\n        return filepath, filehash\n    @classmethod\n    def get_record_source_path_and_hash(cls, record: dict):\n        return cls.get_record_file_path_and_hash(record, cls.key.source)\n    @classmethod\n    def get_record_target_path_and_hash(cls, record: dict):\n        return cls.get_record_file_path_and_hash(record, cls.key.target)\n    @classmethod\n    def verify_record_file_hash(cls, record: dict, key: str):\n        filepath, filehash = cls.get_record_file_path_and_hash(record, key)\n        verified = verify_filehash(filepath, filehash)\n        return verified\n    @classmethod\n    def verify_record_source_hash(cls, record: dict):\n        verified = cls.verify_record_file_hash(record, cls.key.source)"
        },
        {
            "comment": "The code defines a class with methods to verify and store record hashes in a database. The `verify_record_target_hash` method checks the target hash of a record, while `construct_upsert_data` constructs data for upserting into the database. The `upsert_data` method actually performs the upsert operation. The `CacheContextManager` is a context manager used to interact with the cache database.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/cache_db_context.py\":108-144",
            "content": "        return verified\n    @classmethod\n    def verify_record_target_hash(cls, record: dict):\n        verified = cls.verify_record_file_hash(record, cls.key.target)\n        return verified\n    @classmethod\n    def construct_upsert_data(\n        cls, source_path: str, source_hash: str, target_path: str, target_hash: str\n    ):\n        data = {\n            cls.key.source: {\n                cls.subkey.path: source_path,\n                cls.subkey.hash: source_hash,\n            },\n            cls.key.target: {\n                cls.subkey.path: target_path,\n                cls.subkey.hash: target_hash,\n            },\n        }\n        return data\n    def upsert_data(\n        self, source_path: str, source_hash: str, target_path: str, target_hash: str\n    ):\n        data = self.construct_upsert_data(\n            source_path, source_hash, target_path, target_hash\n        )\n        self.db.upsert(\n            data,\n            cond=self.source_path_eq(source_path),\n        )\n@contextmanager\ndef CacheContextManager(db_path: str):"
        },
        {
            "comment": "This code contains functions to generate and verify target file paths and hashes. It uses a CacheManager for retrieving record targets, verifies file hashes using the hash_file function, and provides beartype decorators for type checking. The generate_and_hash_target function generates and hashes a target file, while the verify_record_target function retrieves the record's target path and hash from the CacheManager and verifies it using verify_filehash.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/cache_db_context.py\":145-183",
            "content": "    manager = CacheManager(db_path)\n    try:\n        yield manager\n    finally:\n        del manager\n@beartype\ndef verify_filehash(filepath: str, filehash: str):\n    if os.path.exists(filepath):\n        current_hash = hash_file(filepath)\n        if current_hash == filehash:\n            return True\n    return False\nclass TargetGeneratorParameter(pydantic.BaseModel):\n    target_dir_path: str\n    source_path: str\n@beartype\ndef generate_and_hash_target(\n    param: TargetGeneratorParameter,\n    target_path_generator: Callable[[TargetGeneratorParameter], str],\n    target_file_geneator: Callable[[str, str], Any],\n):\n    target_path = target_path_generator(param)\n    _ = target_file_geneator(param.source_path, target_path)\n    target_hash = hash_file(target_path)\n    return target_path, target_hash\n@beartype\ndef verify_record_target(record: dict, manager: CacheManager):\n    record_target_path, record_target_hash = manager.get_record_target_path_and_hash(\n        record\n    )\n    target_verified = verify_filehash(record_target_path, record_target_hash)"
        },
        {
            "comment": "This code defines two functions. The first function, \"fix\\_record\\_if\\_source\\_filename\\_link\\_is\\_missing\", checks if the given source file path and hash match a record with the specified target file path and hash in the cache. If not found, it adds the new record to the cache. The second function, \"check\\_if\\_target\\_exists\\_with\\_source\\_in\\_record\", verifies if a target exists in the cache with a matching source file path and hash. It returns the verified status, target file path, and target file hash if successful.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/cache_db_context.py\":184-217",
            "content": "    return target_verified, record_target_path, record_target_hash\n@beartype\ndef fix_record_if_source_filename_link_is_missing(\n    source_path: str,\n    source_hash: str,\n    record_target_path: str,\n    record_target_hash: str,\n    manager: CacheManager,\n):\n    pointed_record = manager.db.get(\n        manager.source_path_eq(source_path)\n        and manager.target_path_eq(record_target_path)\n    )\n    if pointed_record is None:\n        # insert record\n        manager.upsert_data(\n            source_path, source_hash, record_target_path, record_target_hash\n        )\n@beartype\ndef check_if_target_exists_with_source_in_record(\n    record: dict, source_path: str, source_hash: str, manager: CacheManager\n):\n    has_record = False\n    target_verified, record_target_path, record_target_hash = verify_record_target(\n        record, manager\n    )\n    if target_verified:\n        # we should check if we have source filename pointing to this target.\n        fix_record_if_source_filename_link_is_missing(\n            source_path, source_hash, record_target_path, record_target_hash, manager"
        },
        {
            "comment": "The code checks if a source file exists in a record and returns the target path if it does. It also defines classes for parameters used in iterating sources and generating targets.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/cache_db_context.py\":218-250",
            "content": "        )\n        has_record = True\n    else:\n        manager.db.remove(manager.target_path_eq(record_target_path))\n    return has_record, record_target_path\n@beartype\ndef check_if_source_exists_in_record(\n    source_path: str, manager: CacheManager\n) -> Tuple[bool, str, Optional[str]]:\n    has_record = False\n    record_target_path = None\n    record, source_hash = manager.get_record_by_computing_source_hash(source_path)\n    if record:\n        has_record, record_target_path = check_if_target_exists_with_source_in_record(\n            record, source_path, source_hash, manager\n        )\n    return has_record, source_hash, record_target_path\nclass SourceIteratorAndTargetGeneratorParam(pydantic.BaseModel):\n    source_dir_path: str\n    target_dir_path: str\n    db_path: str\n@beartype\ndef iterate_source_dir_and_generate_to_target_dir(\n    param: SourceIteratorAndTargetGeneratorParam,\n    source_walker: Callable[[str], Iterable[tuple[Any, str]]],\n    target_path_generator: Callable[[TargetGeneratorParameter], str],\n    target_file_geneator: Callable[[str, str], Any],"
        },
        {
            "comment": "This code defines two functions: `process_source_and_return_target_path` and `get_target_path_by_checking_manager_or_processing`. The former generates a target path and hash for a given source path and source hash, then inserts the data into the cache manager. The latter checks if the source path exists in the cache manager's records; if not, it calls `process_source_and_return_target_path` to generate the target path.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/cache_db_context.py\":251-280",
            "content": "    join_source_dir: bool = True,\n) -> list[str]:\n    @beartype\n    def process_source_and_return_target_path(\n        manager: CacheManager,\n        source_path: str,\n        source_hash: str,\n    ):\n        target_path, target_hash = generate_and_hash_target(\n            TargetGeneratorParameter(\n                target_dir_path=param.target_dir_path, source_path=source_path\n            ),\n            target_path_generator,\n            target_file_geneator,\n        )\n        manager.upsert_data(source_path, source_hash, target_path, target_hash)\n        return target_path\n    @beartype\n    def get_target_path_by_checking_manager_or_processing(\n        manager: CacheManager, source_path: str\n    ) -> str:\n        (\n            has_record,\n            source_hash,\n            record_target_path,\n        ) = check_if_source_exists_in_record(source_path, manager)\n        if not has_record or not isinstance(record_target_path, str):\n            target_path = process_source_and_return_target_path(\n                manager,"
        },
        {
            "comment": "Function 'process_file_and_append_to_cache_paths' takes in a file path and cache manager, checks if the file is already processed, and appends its target path to the list of processed cache paths.\n\nFunction 'get_processed_cache_paths' initializes an empty list, processes files using CacheContextManager, and appends their target paths to the list of processed cache paths.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/cache_db_context.py\":281-308",
            "content": "                source_path,\n                source_hash,\n            )\n        else:\n            target_path = record_target_path\n        return target_path\n    @beartype\n    def process_file_and_append_to_cache_paths(\n        manager: CacheManager, fpath: str, processed_cache_paths: list[str]\n    ):\n        source_path = (\n            os.path.join(param.source_dir_path, fpath) if join_source_dir else fpath\n        )\n        target_path = get_target_path_by_checking_manager_or_processing(\n            manager, source_path\n        )\n        processed_cache_paths.append(target_path)\n    @beartype\n    def get_processed_cache_paths():\n        processed_cache_paths: list[str] = []\n        with CacheContextManager(param.db_path) as manager:\n            # to make this accountable, we need to convert it into list.\n            items = list(source_walker(param.source_dir_path))\n            items_count = len(items)\n            print(f\"\\n>>>> PROCESSING PROGRESS: 0/{items_count}\")\n            for i, (_, fpath) in enumerate(items):"
        },
        {
            "comment": "Function `make_and_return_dir_path` creates a new directory at the specified path and returns it. Function `make_source_and_target_dirs` uses `make_and_return_dir_path` to create source and target directories under the given base directory, then returns them as a tuple. Function `read_file` reads the content of a file at the specified path.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/cache_db_context.py\":309-345",
            "content": "                print(\"processing:\", fpath)\n                # if file_empty(fpath):\n                #     continue\n                process_file_and_append_to_cache_paths(\n                    manager, fpath, processed_cache_paths\n                )\n                print(f\"\\n>>>> PROCESSING PROGRESS: {i+1}/{items_count}\")\n        return processed_cache_paths\n    return get_processed_cache_paths()\n@beartype\ndef make_and_return_dir_path(base_dir: str, subdir: str):\n    dirpath = os.path.join(base_dir, subdir)\n    os.mkdir(dirpath)\n    return dirpath\n@beartype\ndef make_source_and_target_dirs(base_dir: str):\n    @beartype\n    def make_and_return_dir_path_under_base_dir(subdir: str):\n        return make_and_return_dir_path(base_dir, subdir)\n    source_dir = make_and_return_dir_path_under_base_dir(\"source\")\n    target_dir = make_and_return_dir_path_under_base_dir(\"target\")\n    return source_dir, target_dir\n@beartype\ndef read_file(fpath: str):\n    with open(fpath, \"r\", encoding=UTF8) as f:\n        return f.read()\n@beartype"
        },
        {
            "comment": "Function to write a file, function for generating test target file paths using provided parameters, and function for preparing test parameter.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/cache_db_context.py\":346-376",
            "content": "def write_file(fpath: str, content: str):\n    with open(fpath, \"w+\", encoding=UTF8) as f:\n        f.write(content)\ndef test_main():\n    test_file_basename = \"test_file.txt\"\n    test_db_basename = \"cache.db\"\n    test_source_content = \"test\"\n    @beartype\n    def test_target_file_generator(source_path: str, target_path: str):\n        content = read_file(source_path)\n        write_file(target_path, content)\n    @beartype\n    def join_dir_path_with_test_file_basename(dir_path: str):\n        ret = os.path.join(dir_path, test_file_basename)\n        return ret\n    @beartype\n    def test_target_path_generator(param: TargetGeneratorParameter):\n        ret = join_dir_path_with_test_file_basename(param.target_dir_path)\n        return ret\n    @beartype\n    def prepare_test_param(temp_dir: str):\n        source_dir, target_dir = make_source_and_target_dirs(temp_dir)\n        db_path = os.path.join(temp_dir, test_db_basename)\n        param = SourceIteratorAndTargetGeneratorParam(\n            source_dir_path=source_dir, target_dir_path=target_dir, db_path=db_path"
        },
        {
            "comment": "The code defines functions for generating a test source walker, writing test content to file, asserting file content as test content, and preparing a test file context. These functions work together to perform tests on source and target files with a common structure and content.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/cache_db_context.py\":377-408",
            "content": "        )\n        return param\n    @beartype\n    def generate_test_source_walker(source_dir: str):\n        @beartype\n        def test_source_walker(dirpath: str):\n            return [(dirpath, it) for it in os.listdir(source_dir)]\n        return test_source_walker\n    @beartype\n    def write_test_content_to_file(file_path: str):\n        write_file(file_path, test_source_content)\n    @beartype\n    def assert_file_content_as_test_content(file_path):\n        test_target_content = read_file(file_path)\n        assert test_target_content == test_source_content\n    @contextmanager\n    @beartype\n    def prepare_test_file_context(source_dir: str, target_dir: str):\n        test_source_path = join_dir_path_with_test_file_basename(source_dir)\n        test_target_path = join_dir_path_with_test_file_basename(target_dir)\n        write_test_content_to_file(test_source_path)\n        try:\n            yield\n        finally:\n            assert_file_content_as_test_content(test_target_path)\n    def test_and_assert(param: SourceIteratorAndTargetGeneratorParam):"
        },
        {
            "comment": "The code is setting up a test environment in temporary directories, generating test parameters, iterating through source and target directories, and then asserting the test results. It also includes a function to generate a test source walker and two generators for target paths and files. Finally, it prints \"test passed\" if the test is successful.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/cache_db_context.py\":409-428",
            "content": "        with prepare_test_file_context(param.source_dir_path, param.target_dir_path):\n            test_source_walker = generate_test_source_walker(param.source_dir_path)\n            iterate_source_dir_and_generate_to_target_dir(\n                param,\n                test_source_walker,\n                test_target_path_generator,\n                test_target_file_generator,\n            )\n    def test_in_temporary_directory():\n        with tempfile.TemporaryDirectory() as temp_dir:\n            param = prepare_test_param(temp_dir)\n            test_and_assert(param)\n    test_in_temporary_directory()\n    print(\"test passed\")\nif __name__ == \"__main__\":\n    test_main()"
        }
    ]
}