{
    "summary": "This code generates prompts for creating questions and answers about file content using Pydantic schema, JSON format, and markdown. It includes functions to gather context for software project-related questions and returns previously defined prompts.",
    "details": [
        {
            "comment": "This code contains prompts for generating technical explanations of the code and its usage in the larger project. The FILE_PROMPT provides a detailed objective prompt with an upper limit of 300 words, while the FOLDER_PROMPT offers concise information under 400 words about how the code fits into the project. The output should be in markdown format and tailored to developers who may be curious about the code.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/vectorstore_embedding_chat_rag/prompts.py\":0-22",
            "content": "FILE_RETRIEVER_OBJECTIVE_PROMPT = \"\"\"Write a detailed technical explanation of what this code does.\nFocus on the high-level purpose of the code and how it may be used in the larger project.\n\"\"\"\nFOLDER_RETRIEVER_OBJECTIVE_PROMPT = \"\"\"Write a technical explanation of what the code in this file does and how it might fit into the larger project or work with other parts of the project.\nGive examples of how this code might be used. Include code examples where appropriate.\n\"\"\"\nFILE_PROMPT = (\n    f\"\"\"\n{FILE_RETRIEVER_OBJECTIVE_PROMPT.strip()}\nInclude code examples where appropriate. Keep you response between 100 and 300 words.\nDO NOT RETURN MORE THAN 300 WORDS.\nOutput should be in markdown format.\nDo not just list the methods and classes in this file.\n\"\"\",\n)\nFOLDER_PROMPT = (\n    f\"\"\"\n{FOLDER_RETRIEVER_OBJECTIVE_PROMPT.strip()}\nBe concise. Include any information that may be relevant to a developer who is curious about this code.\nKeep you response under 400 words. Output should be in markdown format.\nDo not just list the files and folders in this folder."
        },
        {
            "comment": "This code defines two functions, `generateFileSummaryContextQueriesPrompt` and `generateFileSummaryPrompt`, which generate prompts for generating queries based on a given file summary. The prompts include the file's context and schema information, instructing users to generate 3-5 relevant queries within the specified schema format.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/vectorstore_embedding_chat_rag/prompts.py\":23-69",
            "content": "\"\"\",\n)\nTARGET_AUDIENCE = \"smart developer\"\ndef generateFileSummaryContextQueriesPrompt(\n    schema: str,\n    contentType: str,\n    projectName: str,\n    filePath: str,\n    summary: str,\n    fileRetrieverObjectivePrompt=FILE_RETRIEVER_OBJECTIVE_PROMPT,\n):\n    prompt = f\"\"\"You are acting as a {contentType} documentation expert for a project called {projectName}.\nBelow is the summary from a file located at `{filePath}`. \nYour objective is:\n{fileRetrieverObjectivePrompt}\nFile summary:\n{summary}\nGenerate 3 to 5 queries (NO MORE THAN FIVE) to help you retrieve relevant content to achieve your objective.\nResponse pydantic schema:\n{schema}\nRespond the context queries strictly to the schema, in JSON format:\n\"\"\"\n    return prompt\ndef generateFileSummaryPrompt(\n    contentType: str,\n    projectName: str,\n    filePath: str,\n    summary: str,\n    contextQAPairs: list[tuple[str, str]],\n    filePrompt=FILE_PROMPT,\n):\n    context = \"\\n\".join(\n        [f\"Context to query '{query}':\\n{answer}\\n\" for query, answer in contextQAPairs]\n    )"
        },
        {
            "comment": "This code generates prompts for a documentation expert to answer questions about a specific file content. The first function, `generateFileQuestionsPrompt`, asks the user to provide 3 questions that a target audience might have about the given content type from a file. The second function, `generateFileAnswerPrompt`, prompts the user to respond to these reader questions strictly within a provided Pydantic schema and in JSON format.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/vectorstore_embedding_chat_rag/prompts.py\":70-114",
            "content": "    prompt = f\"\"\"You are acting as a {contentType} documentation expert for a project called {projectName}.\nBelow is the summary and relevant context of {contentType} from a file located at `{filePath}`. \n{filePrompt}\nDo not say \"this file is a part of the {projectName} project\".\nFile summary:\n{summary}\n{context}\nResponse the document in Markdown:\n\"\"\"\n    return prompt\ndef generateFileQuestionsPrompt(\n    schema: str,\n    contentType: str,\n    projectName: str,\n    filePath: str,\n    summary: str,\n    targetAudience: str = TARGET_AUDIENCE,\n):\n    prompt = f\"\"\"You are acting as a {contentType} documentation expert for a project called {projectName}.\nBelow is the {contentType} from a file located at `{filePath}`. \nWhat are 3 questions that a {targetAudience} might have about this {contentType}?\nFile summary:\n{summary}\nResponse pydantic schema:\n{schema}\nRespond the reader questions strictly to the schema, in JSON format:\n\"\"\"\n    return prompt\ndef generateFileAnswerPrompt(\n    contentType: str,\n    projectName: str,\n    filePath: str,"
        },
        {
            "comment": "Function generates a prompt for documentation experts to describe a folder's content and answer related questions in markdown format. The function takes parameters such as schema, content type, project name, folder path, summary, and optional folder retriever objective prompt.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/vectorstore_embedding_chat_rag/prompts.py\":115-157",
            "content": "    summary: str,\n    question: str,\n    context: str,\n    targetAudience: str = TARGET_AUDIENCE,\n):\n    prompt = f\"\"\"You are acting as a {contentType} documentation expert for a project called {projectName}.\nBelow is the {contentType} from a file located at `{filePath}`.\nFile summary:\n{summary}\nThis is a question that a {targetAudience} might have about this {contentType}:\n{question}\nContext about the question:\n{context}\nAnswer the question in 1-2 sentences. Output should be in markdown format.\nRespond the answer to the question in markdown format:\n\"\"\"\n    return prompt\ndef generateFolderSummaryContextQueriesPrompt(\n    schema: str,\n    contentType: str,\n    projectName: str,\n    folderPath: str,\n    summary: str,\n    folderRetrieverObjectivePrompt=FOLDER_RETRIEVER_OBJECTIVE_PROMPT,\n):\n    prompt = f\"\"\"You are acting as a {contentType} documentation expert for a project called {projectName}.\nYou are currently documenting the folder located at `{folderPath}`. \nYour objective is:\n{folderRetrieverObjectivePrompt}\nFolder summary:"
        },
        {
            "comment": "The code defines two functions: `generateFolderSummaryPrompt` and `generateCondensePrompt`. The first function takes parameters such as content type, project name, file path, summary, context pairs, and a folder prompt. It generates a prompt by joining the context queries, summary, and relevant context for a document in Markdown format. The second function takes a chat history and a question as input and generates a prompt to query context for the next question.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/vectorstore_embedding_chat_rag/prompts.py\":159-201",
            "content": "{summary}\nGenerate 3 to 5 queries (NO MORE THAN FIVE) to help you retrieve relevant content to achieve your objective.\nResponse pydantic schema:\n{schema}\nRespond the context queries strictly to the schema, in JSON format:\n\"\"\"\n    return prompt\ndef generateFolderSummaryPrompt(\n    contentType: str,\n    projectName: str,\n    filePath: str,\n    summary: str,\n    contextQAPairs: list[tuple[str, str]],\n    folderPrompt=FOLDER_PROMPT,\n):\n    context = \"\\n\".join(\n        [f\"Context to query '{query}':\\n{answer}\\n\" for query, answer in contextQAPairs]\n    )\n    prompt = f\"\"\"You are acting as a {contentType} documentation expert for a project called {projectName}.\nBelow is the summary and relevant context of {contentType} from a folder located at `{filePath}`. \n{folderPrompt}\nDo not say \"this file is a part of the {projectName} project\".\nFolder summary:\n{summary}\n{context}\nResponse the document in Markdown:\n\"\"\"\n    return prompt\ndef generateCondensePrompt(\n    chat_history: str, question: str\n):  # in order to query context for next question, we generate another query'"
        },
        {
            "comment": "This code defines a function `generateQAPrompt` that generates a prompt for an AI assistant to answer questions related to a software project. The prompt specifies the content type, project name, and target audience, and instructs the assistant to provide conversational answers with GitHub hyperlinks, using only explicitly listed links.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/vectorstore_embedding_chat_rag/prompts.py\":202-224",
            "content": "    prompt = f\"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\nChat History:\n{chat_history}\nFollow Up Input: {question}\nRespond the standalone question:\n\"\"\"\n    return prompt\ndef generateQAPrompt(\n    contentType: str,\n    projectName: str,\n    question: str,\n    context: str,\n    targetAudience: str = TARGET_AUDIENCE,\n):\n    prompt = f\"\"\"You are an AI assistant for a software project called {projectName}. You are trained on all the {contentType} that makes up this project.\nYou are given the following extracted parts of a technical summary of files in a {contentType} and a question. \nProvide a conversational answer with hyperlinks back to GitHub.\nYou should only use hyperlinks that are explicitly listed in the context. Do NOT make up a hyperlink that is not listed.\nInclude lots of {contentType} examples and links to the {contentType} examples, where appropriate.\nAssume the reader is a {targetAudience} but is not deeply familiar with {projectName}."
        },
        {
            "comment": "This function generates a summary prompt for recent chat history, taking query and answer as input. It returns the generated prompt.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/vectorstore_embedding_chat_rag/prompts.py\":225-244",
            "content": "Assume the reader does not know anything about how the project is strucuted or which folders/files are provided in the context.\nDo not reference the context in your answer. Instead use the context to inform your answer.\nIf you don't know the answer, just say \"Hmm, I'm not sure.\" Don't try to make up an answer.\nIf the question is not about the {projectName}, politely inform them that you are tuned to only answer questions about the {projectName}.\nYour answer should be at least 100 words and no more than 300 words.\nDo not include information that is not directly relevant to the question, even if the context includes it.\nAlways include a list of reference links from the context. Links should ONLY come from the context.\nQuestion: {question}\nContext:\n{context}\nAnswer the document in Markdown:\n\"\"\"\n    return prompt\ndef generateRecentChatHistorySummaryPrompt(query, answer):\n    prompt = f\"\"\"You are a professional chat history summarizer. You will produce a chat history summary in 50 words, that both focus "
        },
        {
            "comment": "This code defines a function generateChatHistorySummaryPrompt, which creates a prompt for summarizing chat history in 50 words. The prompt emphasizes capturing key details and factors while being insightful and coherent without using bloat words. It takes two parameters - last_chat_history and recent_chat_history - to focus on the summary.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/vectorstore_embedding_chat_rag/prompts.py\":244-275",
            "content": "on the user prompt and the bot response. DO NOT include bloat words such as 'Both the prompt and the response include'. Capture key details and factors, be insightful. Make your response fluent and coherent, just like a comprehensive summary over the whole chat.\nUser:\n{query}\nBot:\n{answer}\nRespond a chat history summary in 50 words:\n\"\"\"\n    return prompt\ndef generateChatHistorySummaryPrompt(last_chat_history: str, recent_chat_history: str):\n    prompt = f\"\"\"You are a professional chat history summarizer. You will produce a chat history summary in 50 words, that both focus on the last chat history and the recent chat history. DO NOT include bloat words such as 'Both history include'. Capture key details and factors, be insightful. Make your response fluent and coherent, just like a comprehensive summary over the whole chat.\nLast chat history:\n{last_chat_history}\nRecent chat history:\n{recent_chat_history}\nRespond a chat history summary in 50 words:\n\"\"\"\n    return prompt\ndef generateFolderSummaryPrompt():\n    prompt = \"\"\"\"\"\""
        },
        {
            "comment": "This line of code returns the prompt that was previously defined or inputted, allowing for its usage in further stages of the program.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/vectorstore_embedding_chat_rag/prompts.py\":276-276",
            "content": "    return prompt"
        }
    ]
}