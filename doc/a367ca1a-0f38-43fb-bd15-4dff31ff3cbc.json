{
    "summary": "The code manages cache using TinyDB for data management and contains classes for file retrieval, database operations, and upsert constructions. It verifies file hashes, fixes missing filenames, ensures correct target existence, reads/writes file contents, handles test files, creates directories, and performs tests with a `test_and_assert` function.",
    "details": [
        {
            "comment": "This code defines a `CacheManager` class for handling cache data using the TinyDB library. It includes functions to read file contents and calculate MD5 hashes, which are used in the cache management operations. The class initializes a TinyDB database at a specified path and provides methods to construct queries based on different keys.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/cache_db_context.py\":0-49",
            "content": "import hashlib\nimport os\nfrom contextlib import contextmanager\nfrom typing import Any, Callable, Iterable, Optional, Tuple\nimport pydantic\nimport tinydb\nfrom beartype import beartype\nimport tempfile\nUTF8 = \"utf-8\"\n@beartype\ndef read_file_bytes(filename: str):\n    with open(filename, \"rb\") as f:\n        content = f.read()\n    return content\n@beartype\ndef hash_file(filename: str):\n    content = read_file_bytes(filename)\n    hash_obj = hashlib.md5(content)\n    ret = hash_obj.hexdigest()\n    return ret\n@beartype\nclass CacheManager:\n    class subkey:\n        path = \"path\"\n        hash = \"hash\"\n    class key:\n        source = \"source\"\n        target = \"target\"\n    def __init__(self, db_path: str):\n        self.init_db(db_path)\n        self.init_query()\n    def init_db(self, db_path: str):\n        self.db_path = db_path\n        self.db = tinydb.TinyDB(db_path)\n    def init_query(self):\n        self.query = tinydb.Query()\n        self.source_path_query, self.source_hash_query = self.construct_query_by_key(\n            self.key.source"
        },
        {
            "comment": "This code defines a class with methods for comparing the path and hash values of stored files. The class has properties for source and target paths and hashes. It also includes a method to construct queries based on a key and subkey, and methods to compare different properties. Lastly, it has a method to get a record by computing the source hash.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/cache_db_context.py\":50-78",
            "content": "        )\n        self.target_path_query, self.target_hash_query = self.construct_query_by_key(\n            self.key.target\n        )\n    def source_hash_eq(self, other: str):\n        return self.source_hash_query == other\n    def source_path_eq(self, other: str):\n        return self.source_path_query == other\n    def target_hash_eq(self, other: str):\n        return self.target_hash_query == other\n    def target_path_eq(self, other: str):\n        return self.target_path_query == other\n    def construct_query_by_key_and_subkey(self, key: str, subkey: str):\n        key_query = getattr(self.query, key)\n        subkey_query = getattr(key_query, subkey)\n        return subkey_query\n    def construct_query_by_key(self, key: str):\n        path_query = self.construct_query_by_key_and_subkey(key, self.subkey.path)\n        hash_query = self.construct_query_by_key_and_subkey(key, self.subkey.hash)\n        return path_query, hash_query\n    def get_record_by_computing_source_hash(self, source_path: str):\n        source_hash = hash_file(source_path)"
        },
        {
            "comment": "This code defines a class with various methods for retrieving file paths and hashes from a record stored in the database. It provides functions to get source and target file paths along with their corresponding hashes, as well as verify the file hash.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/cache_db_context.py\":79-106",
            "content": "        record = self.db.get(\n            self.source_hash_eq(source_hash)\n        )  # not necessarily directly pointing to the filepath\n        return record, source_hash\n    @classmethod\n    def get_record_file_path_and_hash(cls, record: dict, key: str) -> tuple[str, str]:\n        filepath = record[key][cls.subkey.path]\n        filehash = record[key][cls.subkey.hash]\n        return filepath, filehash\n    @classmethod\n    def get_record_source_path_and_hash(cls, record: dict):\n        return cls.get_record_file_path_and_hash(record, cls.key.source)\n    @classmethod\n    def get_record_target_path_and_hash(cls, record: dict):\n        return cls.get_record_file_path_and_hash(record, cls.key.target)\n    @classmethod\n    def verify_record_file_hash(cls, record: dict, key: str):\n        filepath, filehash = cls.get_record_file_path_and_hash(record, key)\n        verified = verify_filehash(filepath, filehash)\n        return verified\n    @classmethod\n    def verify_record_source_hash(cls, record: dict):\n        verified = cls.verify_record_file_hash(record, cls.key.source)"
        },
        {
            "comment": "This code handles record verification, data construction for upsert operations, and provides a context manager for interacting with a database. It verifies file hashes, constructs data for insert or update operations, and manages a cache database context.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/cache_db_context.py\":107-143",
            "content": "        return verified\n    @classmethod\n    def verify_record_target_hash(cls, record: dict):\n        verified = cls.verify_record_file_hash(record, cls.key.target)\n        return verified\n    @classmethod\n    def construct_upsert_data(\n        cls, source_path: str, source_hash: str, target_path: str, target_hash: str\n    ):\n        data = {\n            cls.key.source: {\n                cls.subkey.path: source_path,\n                cls.subkey.hash: source_hash,\n            },\n            cls.key.target: {\n                cls.subkey.path: target_path,\n                cls.subkey.hash: target_hash,\n            },\n        }\n        return data\n    def upsert_data(\n        self, source_path: str, source_hash: str, target_path: str, target_hash: str\n    ):\n        data = self.construct_upsert_data(\n            source_path, source_hash, target_path, target_hash\n        )\n        self.db.upsert(\n            data,\n            cond=self.source_path_eq(source_path),\n        )\n@contextmanager\ndef CacheContextManager(db_path: str):"
        },
        {
            "comment": "This code manages cache data using a CacheManager, verifies file hashes, generates target files and their hashes, and checks if records match the expected target path and hash.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/cache_db_context.py\":144-182",
            "content": "    manager = CacheManager(db_path)\n    try:\n        yield manager\n    finally:\n        del manager\n@beartype\ndef verify_filehash(filepath: str, filehash: str):\n    if os.path.exists(filepath):\n        current_hash = hash_file(filepath)\n        if current_hash == filehash:\n            return True\n    return False\nclass TargetGeneratorParameter(pydantic.BaseModel):\n    target_dir_path: str\n    source_path: str\n@beartype\ndef generate_and_hash_target(\n    param: TargetGeneratorParameter,\n    target_path_generator: Callable[[TargetGeneratorParameter], str],\n    target_file_geneator: Callable[[str, str], Any],\n):\n    target_path = target_path_generator(param)\n    _ = target_file_geneator(param.source_path, target_path)\n    target_hash = hash_file(target_path)\n    return target_path, target_hash\n@beartype\ndef verify_record_target(record: dict, manager: CacheManager):\n    record_target_path, record_target_hash = manager.get_record_target_path_and_hash(\n        record\n    )\n    target_verified = verify_filehash(record_target_path, record_target_hash)"
        },
        {
            "comment": "This code is defining two functions: `fix_record_if_source_filename_link_is_missing` and `check_if_target_exists_with_source_in_record`.\nThe first function checks if a record with the given source file path exists in the database. If it does not exist, it inserts the record into the database. The second function verifies if the target exists in the record along with its hash and path. If the target exists, it checks if there is a source file pointing to this target.\nBoth functions use the `CacheManager` class for interacting with the database.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/cache_db_context.py\":183-216",
            "content": "    return target_verified, record_target_path, record_target_hash\n@beartype\ndef fix_record_if_source_filename_link_is_missing(\n    source_path: str,\n    source_hash: str,\n    record_target_path: str,\n    record_target_hash: str,\n    manager: CacheManager,\n):\n    pointed_record = manager.db.get(\n        manager.source_path_eq(source_path)\n        and manager.target_path_eq(record_target_path)\n    )\n    if pointed_record is None:\n        # insert record\n        manager.upsert_data(\n            source_path, source_hash, record_target_path, record_target_hash\n        )\n@beartype\ndef check_if_target_exists_with_source_in_record(\n    record: dict, source_path: str, source_hash: str, manager: CacheManager\n):\n    has_record = False\n    target_verified, record_target_path, record_target_hash = verify_record_target(\n        record, manager\n    )\n    if target_verified:\n        # we should check if we have source filename pointing to this target.\n        fix_record_if_source_filename_link_is_missing(\n            source_path, source_hash, record_target_path, record_target_hash, manager"
        },
        {
            "comment": "This code appears to be performing the following tasks:\n1. It checks if a source file exists in a record (217-249): The function `check_if_source_exists_in_record` takes a `source_path` and `manager` object as arguments. It retrieves the record from the manager based on the source path, computes the source hash, and then checks if the target exists with the given source in the record.\n2. It iterates over a source directory and generates files to a target directory (254-307): The `iterate_source_dir_and_generate_to_target_dir` function takes a `param` object, a `source_walker` function, and a `target_path_generator` function as arguments. It iterates over the source directory using the `source_walker` function, generating target paths for each file or folder encountered, and then generates the files in the target directory using the `target_file_geneator` function.\n\nOverall, this code seems to be part of a larger system that manages records related to sources and targets, and performs operations on source directories while generating corresponding target directories.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/cache_db_context.py\":217-249",
            "content": "        )\n        has_record = True\n    else:\n        manager.db.remove(manager.target_path_eq(record_target_path))\n    return has_record, record_target_path\n@beartype\ndef check_if_source_exists_in_record(\n    source_path: str, manager: CacheManager\n) -> Tuple[bool, str, Optional[str]]:\n    has_record = False\n    record_target_path = None\n    record, source_hash = manager.get_record_by_computing_source_hash(source_path)\n    if record:\n        has_record, record_target_path = check_if_target_exists_with_source_in_record(\n            record, source_path, source_hash, manager\n        )\n    return has_record, source_hash, record_target_path\nclass SourceIteratorAndTargetGeneratorParam(pydantic.BaseModel):\n    source_dir_path: str\n    target_dir_path: str\n    db_path: str\n@beartype\ndef iterate_source_dir_and_generate_to_target_dir(\n    param: SourceIteratorAndTargetGeneratorParam,\n    source_walker: Callable[[str], Iterable[tuple[Any, str]]],\n    target_path_generator: Callable[[TargetGeneratorParameter], str],\n    target_file_geneator: Callable[[str, str], Any],"
        },
        {
            "comment": "This code defines two functions for handling source and target paths. The `process_source_and_return_target_path` function generates a new target path and hash based on the given source path, and then stores this information in the manager. The `get_target_path_by_checking_manager_or_processing` function checks if the source path already exists in the manager's records; if not, it calls `process_source_and_return_target_path` to generate a new target path and store it in the manager. It returns the target path.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/cache_db_context.py\":250-279",
            "content": "    join_source_dir: bool = True,\n) -> list[str]:\n    @beartype\n    def process_source_and_return_target_path(\n        manager: CacheManager,\n        source_path: str,\n        source_hash: str,\n    ):\n        target_path, target_hash = generate_and_hash_target(\n            TargetGeneratorParameter(\n                target_dir_path=param.target_dir_path, source_path=source_path\n            ),\n            target_path_generator,\n            target_file_geneator,\n        )\n        manager.upsert_data(source_path, source_hash, target_path, target_hash)\n        return target_path\n    @beartype\n    def get_target_path_by_checking_manager_or_processing(\n        manager: CacheManager, source_path: str\n    ) -> str:\n        (\n            has_record,\n            source_hash,\n            record_target_path,\n        ) = check_if_source_exists_in_record(source_path, manager)\n        if not has_record or not isinstance(record_target_path, str):\n            target_path = process_source_and_return_target_path(\n                manager,"
        },
        {
            "comment": "This code is a part of the cache management process in a computer control system. It retrieves file paths, checks if they already exist in the cache, and adds them to the cache if necessary. The `process_file_and_append_to_cache_paths` function determines the source and target paths for each file, and appends the target path to the list of processed cache paths. The `get_processed_cache_paths` function initializes an empty list of processed cache paths, creates a CacheContextManager object, walks through the source directory, processing each item, and appending the processed cache paths to the list. The progress is displayed as items are being processed.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/cache_db_context.py\":280-307",
            "content": "                source_path,\n                source_hash,\n            )\n        else:\n            target_path = record_target_path\n        return target_path\n    @beartype\n    def process_file_and_append_to_cache_paths(\n        manager: CacheManager, fpath: str, processed_cache_paths: list[str]\n    ):\n        source_path = (\n            os.path.join(param.source_dir_path, fpath) if join_source_dir else fpath\n        )\n        target_path = get_target_path_by_checking_manager_or_processing(\n            manager, source_path\n        )\n        processed_cache_paths.append(target_path)\n    @beartype\n    def get_processed_cache_paths():\n        processed_cache_paths: list[str] = []\n        with CacheContextManager(param.db_path) as manager:\n            # to make this accountable, we need to convert it into list.\n            items = list(source_walker(param.source_dir_path))\n            items_count = len(items)\n            print(f\"\\n>>>> PROCESSING PROGRESS: 0/{items_count}\")\n            for i, (_, fpath) in enumerate(items):"
        },
        {
            "comment": "Processing the file and returning processed cache paths.\nCreating a new directory under base_dir with subdir name 'source'.\nCreating a new directory under base_dir with subdir name 'target'.\nReading contents of a file specified by fpath.\nWriting content to a file specified by fpath.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/cache_db_context.py\":308-344",
            "content": "                print(\"processing:\", fpath)\n                process_file_and_append_to_cache_paths(\n                    manager, fpath, processed_cache_paths\n                )\n                print(f\"\\n>>>> PROCESSING PROGRESS: {i+1}/{items_count}\")\n        return processed_cache_paths\n    return get_processed_cache_paths()\n@beartype\ndef make_and_return_dir_path(base_dir: str, subdir: str):\n    dirpath = os.path.join(base_dir, subdir)\n    os.mkdir(dirpath)\n    return dirpath\n@beartype\ndef make_source_and_target_dirs(base_dir: str):\n    @beartype\n    def make_and_return_dir_path_under_base_dir(subdir: str):\n        return make_and_return_dir_path(base_dir, subdir)\n    source_dir = make_and_return_dir_path_under_base_dir(\"source\")\n    target_dir = make_and_return_dir_path_under_base_dir(\"target\")\n    return source_dir, target_dir\n@beartype\ndef read_file(fpath: str):\n    with open(fpath, \"r\", encoding=UTF8) as f:\n        return f.read()\n@beartype\ndef write_file(fpath: str, content: str):\n    with open(fpath, \"w+\", encoding=UTF8) as f:"
        },
        {
            "comment": "This code defines functions for creating and managing test files and directories. It joins a directory path with the test file basename, generates target paths, prepares test parameters by making source and target directories, and initializes a test source walker function.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/cache_db_context.py\":345-378",
            "content": "        f.write(content)\ndef test_main():\n    test_file_basename = \"test_file.txt\"\n    test_db_basename = \"cache.db\"\n    test_source_content = \"test\"\n    @beartype\n    def test_target_file_generator(source_path: str, target_path: str):\n        content = read_file(source_path)\n        write_file(target_path, content)\n    @beartype\n    def join_dir_path_with_test_file_basename(dir_path: str):\n        ret = os.path.join(dir_path, test_file_basename)\n        return ret\n    @beartype\n    def test_target_path_generator(param: TargetGeneratorParameter):\n        ret = join_dir_path_with_test_file_basename(param.target_dir_path)\n        return ret\n    @beartype\n    def prepare_test_param(temp_dir: str):\n        source_dir, target_dir = make_source_and_target_dirs(temp_dir)\n        db_path = os.path.join(temp_dir, test_db_basename)\n        param = SourceIteratorAndTargetGeneratorParam(\n            source_dir_path=source_dir, target_dir_path=target_dir, db_path=db_path\n        )\n        return param\n    @beartype\n    def generate_test_source_walker(source_dir: str):"
        },
        {
            "comment": "This code defines a function `test_source_walker` that returns a list of tuples containing the directory path and each item in the directory. It also has three functions decorated with `@beartype` for writing test content to a file, asserting the file content as test content, and creating a context manager for preparing test files with source and target directories. The main function `test_and_assert` uses the context manager to perform tests.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/cache_db_context.py\":379-406",
            "content": "        @beartype\n        def test_source_walker(dirpath: str):\n            return [(dirpath, it) for it in os.listdir(source_dir)]\n        return test_source_walker\n    @beartype\n    def write_test_content_to_file(file_path: str):\n        write_file(file_path, test_source_content)\n    @beartype\n    def assert_file_content_as_test_content(file_path):\n        test_target_content = read_file(file_path)\n        assert test_target_content == test_source_content\n    @contextmanager\n    @beartype\n    def prepare_test_file_context(source_dir: str, target_dir: str):\n        test_source_path = join_dir_path_with_test_file_basename(source_dir)\n        test_target_path = join_dir_path_with_test_file_basename(target_dir)\n        write_test_content_to_file(test_source_path)\n        try:\n            yield\n        finally:\n            assert_file_content_as_test_content(test_target_path)\n    def test_and_assert(param: SourceIteratorAndTargetGeneratorParam):\n        with prepare_test_file_context(param.source_dir_path, param.target_dir_path):"
        },
        {
            "comment": "This code generates test source walker, iterates over source directory, and then generates to target directory. It also performs a test in a temporary directory and asserts the result. Finally, it prints \"test passed\" if the test passes.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/cache_db_context.py\":407-425",
            "content": "            test_source_walker = generate_test_source_walker(param.source_dir_path)\n            iterate_source_dir_and_generate_to_target_dir(\n                param,\n                test_source_walker,\n                test_target_path_generator,\n                test_target_file_generator,\n            )\n    def test_in_temporary_directory():\n        with tempfile.TemporaryDirectory() as temp_dir:\n            param = prepare_test_param(temp_dir)\n            test_and_assert(param)\n    test_in_temporary_directory()\n    print(\"test passed\")\nif __name__ == \"__main__\":\n    test_main()"
        }
    ]
}