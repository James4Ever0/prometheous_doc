{
    "summary": "This code utilizes an external package's module to generate file titles based on metadata and content using LLM. It updates cache if necessary, stores generated titles in `result_dict`, and processes data to generate titles for file summaries before splitting them into separate JSON files.",
    "details": [
        {
            "comment": "This code generates a title for files in a given source directory based on metadata and file content. It uses the llm_context module from an external package and split_utils to process the data. The code reads metadata from \"metadata.json\" and data files named by their index, then generates titles if needed and only displays them if they exist.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/title_generator/main.py\":0-40",
            "content": "# generate title\n# create /cache_title.json, /metadata_title.json, /data/titles/<number>.json\n# hash by comment, cache by path identifier and comment hash\n# identify those identical comments (file that only has one segment), only give title to file not segment\n# only display title if exists\nimport os\nimport argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"-s\", \"--source_dir\", type=str, required=True)\nargs = parser.parse_args()\n# the only parameter.\nsource_dir = args.source_dir\nassert os.path.exists(source_dir)\nassert os.path.isdir(source_dir)\nassert os.path.isabs(source_dir)\nimport json\nimport sys\nsys.path.append(os.path.join(os.path.abspath(os.path.dirname(__file__)), \"../\"))\nfrom llm import llm_context\nfrom slice_utils import split_dict_into_chunks\nmetadata = json.loads(open(os.path.join(source_dir, \"metadata.json\"), \"r\").read())\nfile_mapping = metadata[\"file_mapping\"]\nsplit_count = metadata[\"split_count\"]\nproject_name = metadata[\"project_name\"]\ndata = {}\nfor i in range(split_count):\n    new_data = json.loads(open(os.path.join(source_dir, f\"data/{i}.json\"), \"r\").read())"
        },
        {
            "comment": "This code sets up the directory for storing split titles, initializes an empty dictionary for title data, and defines a function to generate a hash key from a summary string. The code also includes error handling for the title split directory not existing or not being a directory.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/title_generator/main.py\":41-86",
            "content": "    data.update(new_data)\ndef strip_quote(s: str):\n    if s[0] == s[-1]:\n        if s[0] in ['\"', \"'\"]:\n            return s[1:-1].strip()\n    return s.strip().strip(\".\")\nfrom tinydb import TinyDB, Query\ncache_title = TinyDB(os.path.join(source_dir, \"cache_title.json\"))\ntitle_split_dir = os.path.join(source_dir, \"data/titles\")\nmetadata_title_path = os.path.join(source_dir, \"metadata_title.json\")\nimport shutil\nif not os.path.exists(title_split_dir):\n    os.makedirs(title_split_dir)\nelse:\n    shutil.rmtree(title_split_dir)\n    os.makedirs(title_split_dir)\nif not os.path.isdir(title_split_dir):\n    raise Exception(\n        f\"'{title_split_dir}' (where splited titles stored) must be a directory\"\n    )\n# structure:\n# [filepath] [summary] [code] [comment] ...\ntitle_data = {}\nfile_mapping_detail = {}\ndata_count = len(data.keys())\nimport hashlib\ndef hash_key(summary: str):\n    enc = summary.strip()\n    if enc:\n        # Generate a hash for the given summary\n        hash_object = hashlib.md5(enc.encode())\n        return hash_object.hexdigest()"
        },
        {
            "comment": "This code defines a function `ask_llm_for_title` that utilizes a Language Model (LLM) to generate a title for a given content and path. The function `generate_title_and_update_to_result` uses this LLM function to generate titles, checks if the title already exists in cache, and updates it if necessary. It also stores the generated titles in the `result_dict`.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/title_generator/main.py\":89-117",
            "content": "def ask_llm_for_title(path: str, comment: str):\n    init_prompt = \"\"\"You are a professional title writer. You can write a concise, conclusive and meaningful title within 3 to 7 words. You will be given a piece of content, a path that refers to the content and produce a single title.\n\"\"\"\n    with llm_context(init_prompt) as model:\n        prompt = f\"\"\"Content:\n{comment}\nPath of the content: {path}\nTitle within 3 to 7 words (do not quote the title, just write it out):\n\"\"\"\n        ret = model.run(prompt).strip()\n        ret = strip_quote(ret)\n    return ret\ndef generate_title_and_update_to_result(\n    path: str, comment: str, result_dict: dict[str, str]\n):\n    comment_hash = hash_key(comment)\n    doc = cache_title.get((Query().hash == comment_hash) and (Query().path == path))\n    if doc:\n        mtitle = doc[\"title\"]\n    else:\n        mtitle = ask_llm_for_title(path, comment)\n        cache_title.upsert(\n            dict(path=path, hash=comment_hash, title=mtitle), cond=Query().path == path\n        )\n    result_dict[path] = mtitle"
        },
        {
            "comment": "This code iterates over a file mapping and checks for the next item. It calculates the start and end positions for each file, determining how many splits to make based on the difference between the end and start positions. This information is stored in a dictionary called file_mapping_detail. The file count is determined and printed as processing progress. Finally, it generates splits for the file summary title.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/title_generator/main.py\":120-147",
            "content": "for k, v in file_mapping.items():\n    # end_id is exclusive.\n    if str(int(k) + 1) in file_mapping.keys():\n        end_id = int(file_mapping[str(int(k) + 1)][\"entry_id\"])\n    elif (int(k) + 1) == len(file_mapping.items()):\n        end_id = data_count\n    else:\n        raise Exception(\n            f\"Missing next item for index {k}, file count {len(file_mapping.items())}\"\n        )\n    file_mapping_detail[k] = {\n        \"filepath\": v[\"filepath\"],\n        \"span\": {\"start\": int(v[\"entry_id\"]), \"end\": end_id},\n    }\nfile_count = len(file_mapping.keys())\nprint(f\"\\n>>>> PROCESSING PROGRESS: 0/{file_count}\")\n# print(file_mapping_detail)\n# with open(\"/tmp/file_mapping.txt\", \"w+\") as f:\n#     f.write(str(file_mapping_detail))\n# raise Exception(file_mapping_detail)\n# breakpoint()\nfor i in range(file_count):\n    try:\n        it = file_mapping_detail[str(i)]\n        start, end = it[\"span\"][\"start\"], it[\"span\"][\"end\"]\n        split_count = (end - start - 2) / 2\n        split_count = int(split_count)\n        # generate for file summary title first."
        },
        {
            "comment": "The code processes a chunk of data, generates titles for file summaries and splits, and then stores them in separate JSON files. If the split count is 1, it continues to the next iteration without generating additional titles. The progress is printed at each step, indicating the current processing status.",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/title_generator/main.py\":148-175",
            "content": "        generate_title_and_update_to_result(\n            data[str(start)][\"content\"], data[str(start + 1)][\"content\"], title_data\n        )\n        # raise Exception(start,end,split_count)\n        if split_count == 1:  # only generate for file summary\n            continue\n        else:\n            # generate for splits\n            for j in range(split_count):\n                generate_title_and_update_to_result(\n                    data[str(start + 2 + j * 2)][\"location\"],\n                    data[str(start + 3 + j * 2)][\"content\"],\n                    title_data,\n                )\n    finally:\n        print(f\"\\n>>>> PROCESSING PROGRESS: {i+1}/{file_count}\")\n# split and store file summaries.\nprint(\"Spliting and storing titles...\")\ntitle_split_count = 0\nimport json\nfor i, chunk in enumerate(split_dict_into_chunks(title_data, 300)):\n    title_split_count += 1\n    with open(os.path.join(title_split_dir, f\"{i}.json\"), \"w+\") as f:\n        f.write(json.dumps(chunk, indent=4, ensure_ascii=False))\nprint(\"Storing title metadata...\")"
        },
        {
            "comment": "This code writes the title split count to a file and then prints \"Finished title generation.\"",
            "location": "\"/media/root/Toshiba XG3/works/prometheous_doc/src/document_agi_computer_control/title_generator/main.py\":176-178",
            "content": "with open(metadata_title_path, \"w+\") as f:\n    f.write(json.dumps(dict(split_count=title_split_count)))\nprint(\"Finished title generation.\")"
        }
    ]
}